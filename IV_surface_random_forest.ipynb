{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a749d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy.stats import uniform, randint\n",
    "import math\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split,StratifiedKFold\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9459c72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date     exdate     delta  impl_volatility  time_to_maturity\n",
      "0        2018-02-28 2018-03-16  0.995644         0.687412              16.0\n",
      "8079     2018-02-28 2018-04-04  0.751733        -1.591962              35.0\n",
      "8080     2018-02-28 2018-04-04  0.744376        -1.604212              35.0\n",
      "8081     2018-02-28 2018-04-04  0.736836        -1.617117              35.0\n",
      "8082     2018-02-28 2018-04-04  0.728928        -1.629789              35.0\n",
      "...             ...        ...       ...              ...               ...\n",
      "21457096 2023-02-27 2023-02-28 -0.000468        -0.037699               1.0\n",
      "21457097 2023-02-27 2023-02-28 -0.000472        -0.046069               1.0\n",
      "21457098 2023-02-27 2023-02-28 -0.000480        -0.062996               1.0\n",
      "21456993 2023-02-27 2023-02-28  0.000654        -0.372365               1.0\n",
      "21468994 2023-02-27 2023-12-29 -0.001588        -0.386937             305.0\n",
      "\n",
      "[19198643 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = 'newd.csv'\n",
    "\n",
    "Data = pd.read_csv(df)[['date','exdate','delta','impl_volatility']] #try using more features later\n",
    "Data['date'] = pd.to_datetime(Data['date'])\n",
    "Data['exdate'] = pd.to_datetime(Data['exdate'])\n",
    "\n",
    "\n",
    "sdate = datetime.datetime(2018,2,28)\n",
    "edate = datetime.datetime(2023,2,28)\n",
    "\n",
    "\n",
    "Data = Data[Data['date'] < edate] #change this line if we need more complicated set of data\n",
    "Data = Data[Data['date'] >= sdate]\n",
    "\n",
    "Data['time_to_maturity'] = (Data['exdate']-Data['date']).astype('int64')/10**9/3600/24\n",
    "Data = Data.dropna()\n",
    "\n",
    "Data\n",
    "Data = Data.dropna()\n",
    "\n",
    "Data = Data.sort_values(by='date')\n",
    "Data['impl_volatility'] = np.log(Data['impl_volatility'])\n",
    "print(Data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16eb98a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        impl_volatility   R-squared:                       0.070\n",
      "Model:                            OLS   Adj. R-squared:                  0.070\n",
      "Method:                 Least Squares   F-statistic:                 5.797e+05\n",
      "Date:                Tue, 28 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        10:36:14   Log-Likelihood:            -1.2384e+07\n",
      "No. Observations:            15358914   AIC:                         2.477e+07\n",
      "Df Residuals:                15358911   BIC:                         2.477e+07\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               -1.3322      0.000  -7955.251      0.000      -1.333      -1.332\n",
      "delta                0.2477      0.000   1025.980      0.000       0.247       0.248\n",
      "time_to_maturity    -0.0003   7.74e-07   -336.280      0.000      -0.000      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                  1583137.582   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2508591.081\n",
      "Skew:                           0.756   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.277   Cond. No.                         377.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Mean Squared Error: 0.2943\n",
      "R-squared: 0.0696\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Futures(X) we would be using and response variable(y)\n",
    "\n",
    "features = ['delta', 'time_to_maturity']\n",
    "X = Data[features]\n",
    "y = Data['impl_volatility']\n",
    "\n",
    "# Add a constant term for the linear regression\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = sm.OLS(y_train, X_train)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the linear regression model\n",
    "print(result.summary())\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = result.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ebe35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2943\n",
      "R-squared: 0.0696\n",
      "Coefficients: [ 0.14186466 -0.04650144]\n",
      "Intercept: -1.3293617199557357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Futures(X) we would be using and response variable(y)\n",
    "features = ['delta', 'time_to_maturity']\n",
    "X = Data[features]\n",
    "y = Data['impl_volatility']\n",
    "\n",
    "# Standardize features (optional but can be beneficial for some algorithms)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(f'Coefficients: {model.coef_}')\n",
    "print(f'Intercept: {model.intercept_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be915f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.1511\n",
      "R-squared: 0.5222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Select relevant features and target variable\n",
    "features = ['delta', 'time_to_maturity']\n",
    "X = Data[features]\n",
    "y = Data['impl_volatility']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d58e5cf",
   "metadata": {},
   "source": [
    "\n",
    "## Code below is not working for some reason. Ignore beyond this line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cafb6f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (pywrap_tensorflow_internal.py, line 114)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3457\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/var/folders/h3/cyrs85856qq55m7y7mmnbp7w0000gn/T/ipykernel_58612/3869882390.py\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import tensorflow as tf\n",
      "  File \u001b[1;32m\"/opt/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\"\u001b[0m, line \u001b[1;32m24\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \u001b[1;32m\"/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\"\u001b[0m, line \u001b[1;32m49\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from tensorflow.python import pywrap_tensorflow\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\"\u001b[0;36m, line \u001b[0;32m58\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from tensorflow.python.pywrap_tensorflow_internal import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\"\u001b[0;36m, line \u001b[0;32m114\u001b[0m\n\u001b[0;31m    def TFE_ContextOptionsSetAsync(arg1, async):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "df = 'newd.csv'\n",
    "\n",
    "Data = pd.read_csv(df)[['date','exdate','delta','impl_volatility']] #try using more features later\n",
    "Data['date'] = pd.to_datetime(Data['date'])\n",
    "Data['exdate'] = pd.to_datetime(Data['exdate'])\n",
    "\n",
    "\n",
    "sdate = datetime.datetime(2018,2,28)\n",
    "edate = datetime.datetime(2023,2,28)\n",
    "\n",
    "\n",
    "Data = Data[Data['date'] < edate] #change this line if we need more complicated set of data\n",
    "Data = Data[Data['date'] >= sdate]\n",
    "\n",
    "Data['time_to_maturity'] = (Data['exdate']-Data['date']).astype('int64')/10**9/3600/24\n",
    "Data = Data.dropna()\n",
    "\n",
    "Data\n",
    "\n",
    "X = Data[['date', 'exdate', 'delta']]\n",
    "y = Data['impl_volatility']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build a simple neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_nn = model.predict(X_test_scaled)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn.round())\n",
    "print(\"Neural Network Model Accuracy:\", accuracy_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
