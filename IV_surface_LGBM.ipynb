{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947b9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy.stats import uniform, randint\n",
    "import math\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split,StratifiedKFold\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a380819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date     exdate     delta  impl_volatility cp_flag   \n",
      "0       2018-02-28 2018-09-21  0.776262        -1.510561       C  \\\n",
      "780     2018-02-28 2018-06-29  0.169746        -2.120272       C   \n",
      "785     2018-02-28 2018-06-29  0.662646        -1.669820       C   \n",
      "788     2018-02-28 2018-12-21  0.973789        -0.814296       C   \n",
      "791     2018-02-28 2018-04-20  0.951787        -0.809045       C   \n",
      "...            ...        ...       ...              ...     ...   \n",
      "2133073 2023-02-28 2023-03-27  0.459562        -1.640929       C   \n",
      "2113668 2023-02-28 2023-04-21  0.300511        -1.777419       C   \n",
      "2133100 2023-02-28 2023-03-15  0.830740        -1.381148       C   \n",
      "2114552 2023-02-28 2024-01-19  0.905867        -1.186254       C   \n",
      "2118538 2023-02-28 2023-05-31  0.932871        -1.091079       C   \n",
      "\n",
      "         time_to_maturity  \n",
      "0                   205.0  \n",
      "780                 121.0  \n",
      "785                 121.0  \n",
      "788                 296.0  \n",
      "791                  51.0  \n",
      "...                   ...  \n",
      "2133073              27.0  \n",
      "2113668              52.0  \n",
      "2133100              15.0  \n",
      "2114552             325.0  \n",
      "2118538              92.0  \n",
      "\n",
      "[937062 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#-----------------READ DATA----------------\n",
    "datafilename = 'DATA/MockDATA_10percent.csv'\n",
    "\n",
    "Data = pd.read_csv(datafilename)[['date','exdate','delta','impl_volatility',\"cp_flag\"]] #try using more features later\n",
    "Data['date'] = pd.to_datetime(Data['date'])\n",
    "Data['exdate'] = pd.to_datetime(Data['exdate'])\n",
    "\n",
    "\n",
    "#sdate = datetime.datetime(2019,4,13)\n",
    "#edate = datetime.datetime(2019,4,20)\n",
    "\n",
    "\n",
    "#Data = Data[Data['date'] < edate] #change this line if we need more complicated set of data\n",
    "#Data = Data[Data['date'] >= sdate]\n",
    "\n",
    "Data['time_to_maturity'] = (Data['exdate']-Data['date']).astype('int64')/10**9/3600/24\n",
    "Data = Data.dropna()\n",
    "\n",
    "Data\n",
    "Data = Data.dropna()\n",
    "\n",
    "Data = Data.sort_values(by='date')\n",
    "Data['impl_volatility'] = np.log(Data['impl_volatility'])\n",
    "\n",
    "Data = Data[Data[\"cp_flag\"] == \"C\"]\n",
    "print(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d92b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "\n",
    "rate = 0.2\n",
    "rows, columns = Data.shape\n",
    "num = round(rows*(1-rate))\n",
    "\n",
    "idx = Data.index\n",
    "train = Data.loc[idx[0:num]]\n",
    "test = Data.loc[idx[num:]]\n",
    "\n",
    "\n",
    "\n",
    "X_train = train[['delta','time_to_maturity']]\n",
    "X_test = test[['delta','time_to_maturity']]\n",
    "\n",
    "y_train = train['impl_volatility']\n",
    "y_test = test['impl_volatility']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73f40c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1280 candidates, totalling 6400 fits\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.205 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.312 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.085 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.231 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.243 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.113 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.300 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.178 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.079 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.178 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.178 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.085 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.113 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.113 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.161 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.164 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.164 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.178 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.161 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.164 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.161 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.079 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.161 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.103 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.311 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.324 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.103 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.079 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.161 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.079 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.079 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.100 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.280 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.267 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.248 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.240 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.240 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.227 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.100 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.191 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.241 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.240 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.240 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.100 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.306 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.228 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.156 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.154 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.227 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.175 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.309 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.081 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.079 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.100 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.171 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.099 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.312 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.098 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.314 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.078 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.098 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.078 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.098 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.100 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.099 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.099 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.171 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.099 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.078 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.078 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.098 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.078 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.098 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.081 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.106 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.309 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.100 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.099 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.171 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.099 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.078 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.078 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.098 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.078 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.098 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.078 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.324 total time= 3.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.175 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.309 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.101 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.100 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.079 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.099 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.171 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.099 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.171 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.312 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.098 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.098 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.261 total time= 3.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.266 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.258 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.306 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.223 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.268 total time= 3.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.323 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.266 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.322 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.266 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.223 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.227 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.227 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.212 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.239 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.162 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.106 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.081 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.101 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.079 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.171 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.079 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.279 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.234 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.248 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.239 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.153 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.212 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.175 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.081 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.106 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.100 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.079 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.078 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.098 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.078 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.098 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.078 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.314 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.159 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.273 total time= 3.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.280 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.266 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.234 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.213 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.109 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.302 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.081 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.106 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.106 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.303 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.101 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.309 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.100 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.312 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.098 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.078 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.314 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.159 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.159 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.078 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.098 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.314 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.191 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.259 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.258 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.322 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.258 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.248 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.303 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.172 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.081 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.100 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.171 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.100 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.100 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.159 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.159 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.171 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.078 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.314 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.159 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.078 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.279 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.266 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.279 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.266 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.306 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.171 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.078 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.098 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.314 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.078 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.098 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.159 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.171 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.314 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.159 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.078 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.259 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.323 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.258 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.266 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.279 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.223 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.223 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.100 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.227 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.239 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.153 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.175 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.101 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.311 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.078 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.267 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.266 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.322 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.248 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.239 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.239 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.239 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.153 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.302 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.081 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.079 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.100 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.171 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.079 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.171 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.100 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.078 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.314 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.314 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.172 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.098 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.159 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.081 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.100 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.100 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.098 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.078 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.171 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.314 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.159 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.078 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.098 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.314 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.159 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.171 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.078 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.098 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.243 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.079 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.312 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.098 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.078 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.314 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.171 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.314 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.159 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.171 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.078 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.098 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.314 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.171 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.085 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.178 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.078 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.314 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.078 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.243 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.231 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.164 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.113 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.159 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.2, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.159 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.205 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.333 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.295 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.205 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.274 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.231 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.312 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.243 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.312 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.178 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.300 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.079 total time= 7.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.103 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.161 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.103 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.100 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.171 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.178 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.300 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.300 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.300 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.085 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.300 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.307 total time= 7.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.079 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.113 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.164 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.178 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.085 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.161 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.174 total time= 7.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.103 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.161 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.079 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.100 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.100 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.078 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.100 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.078 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.100 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.240 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.228 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.081 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.101 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.103 total time= 7.6min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.174 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.079 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.103 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.174 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.079 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.103 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.161 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.078 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.078 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.173 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.228 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.175 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.081 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.303 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.101 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.100 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.100 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.078 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.100 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.240 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.213 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.227 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.175 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.309 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.100 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.099 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.099 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.100 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.173 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.078 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.100 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.311 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.267 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.240 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.240 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.081 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.160 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.160 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.101 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.099 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.171 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.099 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.099 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.078 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.314 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.100 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.099 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.099 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.079 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.171 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.099 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.099 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.078 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.098 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.314 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.171 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.078 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.324 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.267 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.279 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.191 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.258 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.266 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.223 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.106 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.160 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.101 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.079 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.100 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.171 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.078 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.098 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.098 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.078 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.266 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.266 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.162 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.175 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.081 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.081 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.171 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.079 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.098 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.078 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.098 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.098 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.078 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.098 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.306 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.175 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.079 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.079 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.100 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.314 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.314 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.159 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.159 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.171 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.078 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.314 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.078 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.098 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.314 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.259 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.266 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.213 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.301 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.227 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.081 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.309 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.100 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.171 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.079 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.100 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.171 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.078 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.159 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.171 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.314 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.078 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.323 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.267 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.266 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.100 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.311 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.078 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.098 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.314 total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.159 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.171 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.078 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.279 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.259 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.191 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.258 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.279 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.258 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.109 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.081 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.106 total time=   0.8s\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.098 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.159 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.314 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.159 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.078 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.098 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.314 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.159 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.286 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.328 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.273 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.198 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.267 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.324 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.268 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.280 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.192 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.261 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.267 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.191 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.323 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.258 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.322 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.266 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.234 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.248 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.301 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.162 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.172 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.081 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.171 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.079 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.171 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.079 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.098 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.159 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.171 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.098 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.314 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.078 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.314 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.259 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.322 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.266 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.266 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.279 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.223 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.234 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.248 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.212 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.082 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.109 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.106 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.303 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.081 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.079 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.100 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.171 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.078 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.312 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.172 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.078 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.314 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.171 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.098 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.159 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.078 total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.098 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.314 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.159 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.131 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.209 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.209 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.176 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.190 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.258 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.248 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.223 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.306 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.234 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.228 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.241 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.301 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.239 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.153 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.301 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.175 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.082 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.106 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.172 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.302 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.159 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.081 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.106 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.081 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.309 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.173 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.100 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.159 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.079 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.100 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.079 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.100 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.172 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.099 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.159 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.172 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.314 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.159 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.171 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.078 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.098 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.314 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.159 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.159 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.171 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.078 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.098 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.081 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.106 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.303 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.081 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.106 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.303 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.172 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.081 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.101 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.309 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.173 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.079 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.100 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.172 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.079 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.100 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.171 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.079 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.100 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.159 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.171 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.079 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.099 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.312 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.159 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.078 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.078 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.098 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.314 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.159 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.172 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.078 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.314 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.314 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.159 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.171 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.078 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.098 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.314 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.159 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.171 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.5, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.078 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.227 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.307 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.075 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.307 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.245 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.298 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.200 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.185 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.107 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.185 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.209 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.078 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.075 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.095 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.171 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.245 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.155 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.155 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.166 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.122 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.200 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.185 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.149 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.310 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.102 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.302 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.302 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.095 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.075 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.245 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.245 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.155 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.298 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.298 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.200 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.107 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.168 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.176 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.078 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.096 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.159 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.159 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.075 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.155 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.122 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.200 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.185 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.107 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.107 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.076 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.074 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.169 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.312 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.168 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.168 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.074 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.157 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.074 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.250 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.233 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.233 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.244 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.122 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.149 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.310 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.169 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.168 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.158 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.171 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.168 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.093 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.168 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.168 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.288 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.160 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.169 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.157 total time= 6.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.168 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.312 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.074 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.250 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.236 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.246 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.122 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.288 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.309 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.310 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.166 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.312 total time= 6.0min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.093 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.312 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.157 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.246 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.298 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.298 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.189 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.169 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.244 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.298 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.231 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.166 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.288 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.170 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.310 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.310 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.310 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.186 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.310 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.169 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.270 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.122 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.288 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.184 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.106 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.094 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.108 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.074 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.169 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.168 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.157 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.162 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.176 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.078 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.102 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.078 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.157 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=0.8, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=5, subsample=1;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.131 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.131 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.174 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.174 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.302 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.176 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.302 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.159 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.245 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.155 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.155 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.200 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.185 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.107 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=15, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.253 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.270 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.178 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.237 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=5, num_leaves=20, subsample=1;, score=-0.322 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=5, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.176 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.159 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.159 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.172 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.096 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.307 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.233 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.245 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.200 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.185 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.199 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.107 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.107 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=10, subsample=1;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.227 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=15, subsample=1;, score=-0.131 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.209 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.174 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=10, num_leaves=20, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=5, subsample=1;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=10, subsample=1;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.176 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.302 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=15, subsample=1;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.302 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.162 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.078 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=50, num_leaves=20, subsample=1;, score=-0.102 total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.159 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.096 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.310 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.095 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.246 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.245 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.245 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.155 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.200 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.107 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.185 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.185 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.157 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.169 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=5, subsample=1;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=10, subsample=1;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.159 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=15, subsample=1;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.159 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.172 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.075 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=75, num_leaves=20, subsample=1;, score=-0.096 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=5, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=10, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.171 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.095 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=15, subsample=1;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.095 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=2, n_estimators=100, num_leaves=20, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=5, subsample=1;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.250 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=10, subsample=1;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=15, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.231 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=5, num_leaves=20, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=5, subsample=1;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=10, subsample=1;, score=-0.190 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.200 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=15, subsample=1;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=10, num_leaves=20, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.170 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.074 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.169 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.168 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.093 total time= 2.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.168 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.074 total time= 8.8min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.168 total time= 1.5min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.074 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=5, subsample=1;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.157 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.310 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.311 total time= 2.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.169 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.093 total time= 8.8min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.168 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.312 total time= 1.5min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.231 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.231 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.309 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.310 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.075 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.170 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=10, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.169 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=15, subsample=1;, score=-0.310 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=50, num_leaves=20, subsample=1;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.168 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.074 total time= 2.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.157 total time= 8.8min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.157 total time= 1.5min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.244 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.154 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=5, subsample=1;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=10, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.312 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.168 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=15, subsample=1;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=75, num_leaves=20, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.170 total time= 2.1min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=5, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=10, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.312 total time= 8.8min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.168 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=15, subsample=1;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.093 total time= 1.5min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=5, n_estimators=100, num_leaves=20, subsample=1;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.244 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.160 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.170 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.074 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.310 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.213 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.298 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.122 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.122 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.2;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.259 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=5, subsample=1;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=10, subsample=1;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=15, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=5, num_leaves=20, subsample=1;, score=-0.304 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=5, subsample=1;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=10, subsample=1;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=15, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=10, num_leaves=20, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.098 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=5, subsample=1;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.170 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=10, subsample=1;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.310 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=15, subsample=1;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=50, num_leaves=20, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=5, subsample=1;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=10, subsample=1;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.169 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=15, subsample=1;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=75, num_leaves=20, subsample=1;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.169 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.233 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.231 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.244 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.166 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.298 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.189 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.288 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.186 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.186 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 749650, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.393478\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'n_estimators': 50, 'num_leaves': 20, 'subsample': 0.2}\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.315 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.220 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=1;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.233 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.246 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.246 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.166 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.189 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.151 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.186 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.160 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.094 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.309 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.170 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.074 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.157 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.310 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.093 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.168 total time= 1.3min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.170 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.312 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.307 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.169 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.310 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.093 total time= 1.3min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.311 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.169 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.157 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=5, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.312 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=10, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=15, subsample=1;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=10, n_estimators=100, num_leaves=20, subsample=1;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.5;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=0.8;, score=-0.168 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=5, subsample=1;, score=-0.228 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.2;, score=-0.307 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.5;, score=-0.236 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.250 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=10, subsample=0.8;, score=-0.160 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.246 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.2;, score=-0.156 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.5;, score=-0.156 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=0.8;, score=-0.215 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=15, subsample=1;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.244 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.2;, score=-0.154 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.5;, score=-0.213 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=0.8;, score=-0.304 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=5, num_leaves=20, subsample=1;, score=-0.231 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.215 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.2;, score=-0.122 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.5;, score=-0.166 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=0.8;, score=-0.298 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=5, subsample=1;, score=-0.199 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.2;, score=-0.111 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.5;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=0.8;, score=-0.289 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.204 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.155 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.2;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.108 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.151 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.288 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.173 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.076 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.307 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.170 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.074 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.157 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.158 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.171 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.075 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.094 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.311 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.157 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.168 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.074 total time= 1.3min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.093 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.170 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.312 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.169 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.312 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.312 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.093 total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=10, subsample=1;, score=-0.111 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.5;, score=-0.151 total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=0.8;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.199 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=15, subsample=1;, score=-0.108 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.2;, score=-0.149 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.5;, score=-0.288 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=0.8;, score=-0.184 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.198 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=10, num_leaves=20, subsample=1;, score=-0.106 total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.2;, score=-0.098 total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.5;, score=-0.307 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=0.8;, score=-0.160 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.173 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=5, subsample=1;, score=-0.076 total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.2;, score=-0.309 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.5;, score=-0.158 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.170 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=0.8;, score=-0.074 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=10, subsample=1;, score=-0.094 total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.2;, score=-0.310 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.5;, score=-0.157 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.169 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=0.8;, score=-0.074 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=15, subsample=1;, score=-0.093 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.2;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.5;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.169 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=0.8;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=50, num_leaves=20, subsample=1;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.2;, score=-0.310 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.5;, score=-0.158 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=0.8;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.171 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=5, subsample=1;, score=-0.075 total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.2;, score=-0.093 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.5;, score=-0.311 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=0.8;, score=-0.157 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.169 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=10, subsample=1;, score=-0.074 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.2;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.5;, score=-0.311 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=0.8;, score=-0.157 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=15, subsample=1;, score=-0.074 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.2;, score=-0.093 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.5;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=0.8;, score=-0.157 total time= 1.3min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.168 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=75, num_leaves=20, subsample=1;, score=-0.074 total time=   1.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.2;, score=-0.074 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.5;, score=-0.093 total time=   1.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=0.8;, score=-0.311 total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=5, subsample=1;, score=-0.158 total time=   1.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.169 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.2;, score=-0.074 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.5;, score=-0.093 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=0.8;, score=-0.312 total time=   1.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=10, subsample=1;, score=-0.157 total time=   1.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.169 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.2;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.5;, score=-0.093 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=0.8;, score=-0.312 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=15, subsample=1;, score=-0.157 total time=   1.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.339641\n",
      "[CV 1/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.168 total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.396594\n",
      "[CV 5/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.2;, score=-0.074 total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.412699\n",
      "[CV 4/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.5;, score=-0.093 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.468916\n",
      "[CV 3/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=0.8;, score=-0.312 total time=   1.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 599720, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.349542\n",
      "[CV 2/5] END colsample_bytree=1, max_depth=15, n_estimators=100, num_leaves=20, subsample=1;, score=-0.157 total time=   1.8s\n"
     ]
    }
   ],
   "source": [
    "LGBMR = lgb.LGBMRegressor()\n",
    "\n",
    "#Hyper parameter tuning\n",
    "#brute force grid search \n",
    "\n",
    "pgrid = {\n",
    "    'n_estimators': [5,10,50,75,100],\n",
    "    'num_leaves': [5,10, 15, 20],\n",
    "    'subsample': [0.2,0.5,0.8,1],\n",
    "    'colsample_bytree': [0.2,0.5,0.8,1],\n",
    "    'max_depth':[2,5,10,15]\n",
    "        }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=LGBMR, param_grid=pgrid, scoring='neg_mean_squared_error',n_jobs = 4,cv=5, verbose=3 )\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "bestlgbr = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c0bffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08622938826013876\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'n_estimators': 50, 'num_leaves': 20, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "#fitting on the training set\n",
    "\n",
    "y_p_lgbr = bestlgbr.predict(X_test)\n",
    "\n",
    "goodness = mean_squared_error(y_p_lgbr,y_test)\n",
    "\n",
    "print(goodness)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1576570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import interactive\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#Plot the fitting result\n",
    "interactive(True)\n",
    "#delta = 0.1, 0., 15, 0.2, 0.25, 0.3, 0.35, . . . , 0.9\n",
    "#time to expiry of 1, 2, 3, 4, 8, 12, 18, 52, 104 weeks. \n",
    "D = np.linspace(-1, 1, 41, endpoint=True)\n",
    "T = np.array([1,2,3,4,8,12,18,52,104,156])\n",
    "T_days = T*7 #over time_to_maturity is in days\n",
    "\n",
    "dd,tt = np.meshgrid(D,T_days)\n",
    "\n",
    "\n",
    "X_plot = np.array([dd.flatten(), tt.flatten()]).T\n",
    "\n",
    "y_plot = bestlgbr.predict(X_plot)\n",
    "\n",
    "z = y_plot.reshape(dd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b9f4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xd_test = np.array(X_test['delta'])\n",
    "xt_test = np.array(X_test['time_to_maturity'])\n",
    "\n",
    "test_z = np.array(y_test)\n",
    "\n",
    "\n",
    "xd_train = np.array(X_train['delta'])\n",
    "xt_train = np.array(X_train['time_to_maturity'])\n",
    "\n",
    "train_z = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9edf8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.plot_surface(dd,tt, z,cmap =cm.coolwarm)\n",
    "\n",
    "\n",
    "#ax.scatter(xd_train, xt_train, train_z, color='green')\n",
    "ax.scatter(xd_test, xt_test, test_z, color='red')\n",
    "\n",
    "ax.set_xlabel('delta')\n",
    "ax.set_ylabel('time to maturity')\n",
    "ax.set_zlabel('Volatility');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753d575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
